<!doctype html>
<html itemscope itemtype="http://schema.org/Event">
<head>
  <title itemprop="name">The 2nd Workshop on Machine Learning and Systems (EuroMLSys)</title>

  <meta charset="utf-8">
  <meta name="author" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)" />
  <meta name="description" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)">
  <meta name="viewport" content="width=device-width">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="generator" content="Hugo 0.54.0" />
  <meta property="og:title" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)" />
<meta property="og:description" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://euromlsys.github.io/" />

<meta property="og:image" content="https://euromlsys.github.io/img/euromlsys.png" />


  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://euromlsys.github.io/img/euromlsys.png"/>

<meta name="twitter:title" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)"/>
<meta name="twitter:description" content="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)"/>


  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">
  <link rel="stylesheet" type="text/css" href="/css/main.css">
  <link rel="stylesheet" type="text/css" href="/css/euromlsys.css">

  <script
  src="https://code.jquery.com/jquery-1.12.4.js"
  integrity="sha256-Qw82+bXyGq6MydymqBxNPYTaUXXq7c8v3CwiYwLLNXU="
  crossorigin="anonymous"></script>
  <script type="text/javascript" src="/js/sections.js"></script>

</head>
<body>
  <div class="global">

    <nav id="nav">
  <ul class="wrapper">
    
      <li class="nav-item">
        <a href="#about" id="link-about" title="Home" class="nav-link">
          Home
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#cfp" id="link-cfp" title="Call for Papers" class="nav-link">
          Call for Papers
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#accepted-papers" id="link-accepted-papers" title="Accepted Papers" class="nav-link">
          Accepted Papers
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#schedule" id="link-schedule" title="Program" class="nav-link">
          Program
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#sponsors" id="link-sponsors" title="Sponsors" class="nav-link">
          Sponsors
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#committees" id="link-committees" title="Committees" class="nav-link">
          Committees
        </a>
      </li>
    
      <li class="nav-item">
        <a href="#contact" id="link-contact" title="Contact" class="nav-link">
          Contact
        </a>
      </li>
    
  </ul>
</nav>

<hr>

    

<header class="header">
  <div class="wrapper">
    <h1 class="logo-name">
      <a class="logo-link" href="#" title="The 2nd Workshop on Machine Learning and Systems (EuroMLSys)" itemprop="name">The 2nd Workshop on Machine Learning and Systems (EuroMLSys)</a>
    </h1>
    <h2 class="subtitle">co-located with <a href="https://2022.eurosys.org">EuroSys '22</a></h2>
    <h2 class="tagline">April 5th 2022, Rennes, France</h2>

    <div class="call-action-area">
      

      
    </div>

    <div>
      <img src="/img/euromlsys-white.png">
    </div>
  </div>
</header>

<hr>


    <div class="content" id="content">
      <div class="wrapper">
        
          <section class="about section" id="about">
            <p itemprop="description">
    The recent wave of research focusing on machine intelligence (machine learning and artificial intelligence) and its
    applications has been fuelled by both hardware improvements and deep learning frameworks that simplify the design
    and training of neural models. Advances in AI also accelerate research towards Reinforcement Learning (RL), where
    dynamic control mechanisms are designed to tackle complex tasks. Further, machine learning based optimisation, such
    as Bayesian Optimisation, is gaining traction in the computer systems community where optimisation needs to scale
    with complex and large parameter spaces; areas of interest range from hyperparameter tuning to system configuration
    tuning,
</p>
<p itemprop="description">
    The EuroMLSys workshop will provide a platform for discussing emerging trends in building frameworks, programming
    models, optimisation algorithms, and software engineering tools to support AI/ML applications. At the same time,
    using ML for building such frameworks or optimisation tools will be discussed. EuroMLSys aims to bridge the gap
    between AI research and practice, through a technical program of fresh ideas on software infrastructure, tools,
    design principles, and theory/algorithms (including issues of instability, data efficiency, etc.), from a systems
    perspective. We will also explore potential applications that will take advantage of ML.
</p>

<h4>Key dates</h4>
<p>
<ul class="list">
    <li><b>Paper submission deadline (hard):</b> <s>February 12, 2022</s>  <b>February 17, 2022 (23:59 AoE, UTC-12)</b></li>
    <li><b>Acceptance notification:</b> March 11, 2022</li>
    <li><b>Final paper due:</b> <s>March 18, 2022</s>  <b>March 21, 2022</b></li>
    <li><b>Workshop:</b> April 5, 2022 (full-day workshop)</li>
</ul>
</p>
</p>

<h4>Registration</h4>

<p>
Register via this <a href="https://2022.eurosys.org/registration/">[Link]</a>.
</p>

<h4>Past Editions</h4>
<p>
<ul class="list">
    <li><a href="https://2021.euromlsys.eu">EuroMLSys 2021</a></li>
</ul>
</p>
</p>

          </section>
        
          <section class="cfp section" id="cfp">
            <h2 class="section-title">Call for Papers</h2>

<p>EuroMLSys is an interdisciplinary workshop that brings together researchers in computer architecture, systems and machine learning, along with practitioners who are active in these emerging areas.
</p>
<p>Topics of interest include, but are not limited to, the following:</p>
    <ul class="list">
        <li>Scheduling algorithms for data processing clusters</li>
        <li>Custom hardware for machine learning</li>
        <li> Programming languages for machine learning</li>
        <li>Benchmarking systems (for machine learning algorithms)</li>
        <li>Synthetic input data generation for training</li>
        <li> Systems for training and serving machine learning models at scale</li>
        <li>Graph neural networks</li>
        <li>Neural network compression and pruning in systems</li>
        <li> Systems for incremental learning algorithms</li>
        <li> Large scale distributed learning algorithms in practice</li>
        <li>Database systems for large scale learning</li>
        <li>Model understanding tools (debugging, visualisation, etc.)</li>
        <li>Systems for model-free and model-based Reinforcement Learning
        </li>
        <li>Optimisation in end-to-end deep learning</li>
        <li> System optimisation using Bayesian Optimisation</li>
        <li> Acceleration of model building (e.g.,
            imitation learning in RL)</li>
        <li> Use of probabilistic models in ML/AI
            application</li>
        <li> Learning models for inferring
            network attacks,
            device/service fingerprinting,
            congestion, etc.</li>
        <li> Techniques to collect and
            analyze network data in a
            privacy-preserving manner</li>
        <li> Learning models to capture
            network events and
            control actions</li>
        <li>Machine learning in
            networking (e.g., use of
            Deep RL in networking)</li>
        <li>Analysis of distributed ML algorithms</li>
        <li>Semantics for distributed ML languages</li>
        <li>Probabilistic modelling for distributed ML algorithms</li>
        <li>Synchronisation and state control of distributed ML algorithms</li>
    </ul>
    <p></p>
<p>Accepted papers will be published in the ACM Digital Library (you can opt out from this).</p>

          </section>
        
          <section class="accepted-papers section" id="accepted-papers">
            
<h4>Accepted Papers</h4>
<h5>Oral Presentation</h5>
<p>
<ul class="list">
  <li>
    <b>"Efficient Multi-Class Classification with Duet"</b> —
    <i>Yiren Zhao, Duo Wang, Daniel Bates, Robert Mullins, Mateja Jamnik, and Pietro Lio (The University of Cambridge)</i>
  </li>
  <br>
  <li>
    <b>"Deep learning on microcontrollers: a study on deployment costs and challenges"</b> —
    <i>Filip Svoboda (University of Cambridge); JAVIER FERNANDEZ-MARQUES (University of Oxford); EDGAR LIBERIS, NICHOLAS LANE (University of Cambridge)</i>
  </li>
  <br>
  <li>
    <b>"yslrn: Learning What to Monitor for Efficient Anomaly Detection"</b> —
    <i>Authors: Davide Sanvito, Giuseppe Siracusano, Sharan Santhanam, Roberto Gonzalez, Roberto Bifulco (NEC Laboratories Europe)</i>
  </li>
  <br>
  <li>
    <b>"BoGraph: Structured Bayesian Optimization From Logs for Expensive Systems with Many"</b> —
    <i>Sami Alabed, Eiko Yoneki (University of Cambridge)</i>
  </li>
  <br>
  <li>
    <b>"Reinforcement Learning for Resource Management in Multi-tenant Serverless Platforms"</b> —
    <i>Haoran Qiu, Weichao Mao, Archit Patke (University of Illinois at Urbana-Champaign); Chen Wang, Hubertus Franke (IBM Thomas J. Watson Research Center); Zbigniew Kalbarczyk, Tamer Başar, Ravishankar K. Iyer (University of Illinois at Urbana-Champaign)</i>
  </li>
  <br>
  <li>
    <b>"Rapid Model Architecture Adaption for Meta-Learning"</b> —
    <i>Yiren Zhao (University of Cambridge); Xitong Gao (Shenzhen Institutes of Advanced Technology); Ilia Shumailov (University of Cambridge); Nicolo Fusi (Microsoft); Robert Mullins (University of Cambridge)</i>
  </li>
  <br>
  <li>
    <b>"How Reinforcement Learning Systems Fail and What to do About It"</b> —
    <i>Pouya Hamdanian (MIT); Malte Schwarzkopf (Brown University); Siddhartha Sen (Microsoft Research); Mohammad Alizadeh (MIT CSAIL)</i>
  </li>
  <br>
  <li>
    <b>"On the Impact of Device and Behavioral Heterogeneity in Federated Learning"</b> —
    <i>Ahmed M. Abdelmoniem (Queen Mary University of London); Chen-Yu Ho, Pantelis Papageorgiou, Marco Canini (KAUST)</i>
  </li>
  <br>
  <li>
    <b>"slo-nns: Service Level Objective-Aware Neural Networks"</b> —
    <i> Daniel Mendoza, Caroline Trippel (Stanford University)</i>
  </li>
  <br>
  <li>
    <b>"FlexHTTP: An Intelligent and Scalable HTTP Version Selection System"</b> —
    <i>Mengying Zhou, Zheng Li, Shihan Lin, Xin Wang, Yang Chen (Fudan University)</i>
  </li>
  <br>
  <li>
    <b>"Live Video Analytics as a Service"</b> —
    <i>Guilherme Henrique Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, Lin Wang (Vrije Universiteit Amsterdam)</i>
  </li>
  <br>
  <p></p>
  <h5>Poster Presentation</h5>
  <li>
    <b>"dSyncPS: Delayed Synchronization for Dynamic Deployment of Distributed Machine Learning"</b> —
    <i></i>Yibo Guo, An Wang (Case Western Reserve University)</i>
  </li>
  <br>
  <li>
    <b>"Scaling Knowledge Graph Embedding Models"</b> —
    <i>Nasrullah Sheikh, Xiao Qin, Berthold Reinwald (IBM Research Almaden); Chuan Lei (Instacart)</i>
  </li>
  <br>
  <li>
    <b>"Data Selection for Efficient Model Update in Federated Learning"</b> —
    <i>Hongrui Shi, Valentin Radu (University of Sheffield)</i>
  </li>
  <br>
  <li>
    <b>"DyFiP: Explainable AI-based Dynamic Filter Pruning of Convolutional Neural Networks"</b> —
    <i>Muhammad Sabih, Frank Hannig, Jürgen Teich (Friedrich-Alexander-Universität Erlangen-Nürnberg)</i>
  </li>
  <br>
  <li>
    <b>"Apache Submarine: A Unified Machine Learning Platform Made Simple"</b> —
    <i>Kai-Hsun Chen (Academia Sinica); Huan-Ping Su (Union.ai); Wei-Chiu Chuang (Cloudera); Hung-Chang Hsiao (National Cheng Kung University); Wangda Tan (Snowflake); Zhankun Tang (Cloudera); Xun Liu (DiDi); Yanbo Liang (Meta Platforms); Wen-Chih Lo (Chunghwa Telecom); Wanqiang Ji (JD.com); Byron Hsu (UC Berkeley); Keqiu Hu (LinkedIn); HuiYang Jian (KE Holdings); Quan Zhou (Ant Group); Chien-Min Wang (Academia Sinica)</i>
  </li>
  <br>
  <li>
    <b>"Temporal Shift Reinforcement Learning"</b> —
    <i>Deepak George Thomas, Tichakorn Wongpiromsarn, Ali Jannesari (Iowa State University)</i>
  </li>
  <br>
</ul>
</p>

          </section>
        
          <section class="schedule section" id="schedule">
            <h2 class="section-title">Program</h2>
<p>Program timezone is CET (UTC+2.00).</p>
<div class="schedule-tbl">
  <table>
    <thead>
      <tr>
        <th class="schedule-time"></th>
        <th class="schedule-slot"></th>
      </tr>
    </thead>
    <tbody>
      
        
          <tr class="schedule-other">
            <td class="schedule-time">09:00</td>
            <td class="schedule-slot">Poster Session</td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              dSyncPS: Delayed Synchronization for Dynamic Deployment of Distributed Machine
            
              <span class="speakers-company">Yibo Guo, An Wang (Case Western Reserve University)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Scaling Knowledge Graph Embedding Models
            
              <span class="speakers-company">Nasrullah Sheikh, Xiao Qin, Berthold Reinwald (IBM Research Almaden); Chuan Lei (Instacart)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Data Selection for Efficient Model Update in Federated Learning
            
              <span class="speakers-company">Hongrui Shi, Valentin Radu (University of Sheffield)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              DyFiP: Explainable AI-based Dynamic Filter Pruning of Convolutional Neural Networks
            
              <span class="speakers-company">Muhammad Sabih, Frank Hannig, Jürgen Teich (Friedrich-Alexander-Universität Erlangen-Nürnberg)</span>
              <span class="schedule-description program">Filter pruning is one of the most effective ways to accelerate CNN. Most of the existing works are focused on the static pruning of CNN filters. In dynamic pruning of CNN filters, existing works are based on the idea of switching between different branches of a CNN or exiting early based on the harndess of a sample. These approaches can reduce the average latency of inference, but they cannot reduce the longest-path latency of inference. In contrast, we present a novel approach of dynamic filter pruning that utilizes explainable AI along with early coarse prediction in the intermediate layers of a CNN. This coarse prediction is performed using a simple branch that is trained to perform top-k classification. The branch either predicts the output class with high confidence, in which case the rest of the computations are left out. Alternatively, the branch predicts the output class to be within a subset of possible output classes. After this coarse prediction, only those filters that are important for this subset of classes are then evaluated. The importances of filters for each output class are obtained using explainable AI. Using this concept of dynamic pruning, we are able not only to reduce the average latency of inference, but also the longest-path latency of inference. Our proposed architecture for dynamic pruning can be deployed on different hardware platforms.
</span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Apache Submarine: A Unified Machine Learning Platform Made Simple
            
              <span class="speakers-company">Kai-Hsun Chen (Academia Sinica); Huan-Ping Su (Union.ai); Wei-Chiu Chuang (Cloudera); Hung-Chang Hsiao (National Cheng Kung University); Wangda Tan (Snowflake); Zhankun Tang (Cloudera); Xun Liu (DiDi); Yanbo Liang (Meta Platforms); Wen-Chih Lo (Chunghwa Telecom); Wanqiang Ji (JD.com); Byron Hsu (UC Berkeley); Keqiu Hu (LinkedIn); HuiYang Jian (KE Holdings); Quan Zhou (Ant Group); Chien-Min Wang (Academia Sinica)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Temporal Shift Reinforcement Learning
            
              <span class="speakers-company">Deepak George Thomas, Tichakorn Wongpiromsarn, Ali Jannesari (Iowa State University)</span>
              <span class="schedule-description program">The function approximators employed by traditional image-based Deep Reinforcement Learning (DRL) algorithms usually lack a temporal learning component and instead focus on learning the spatial component. We propose a technique, Temporal Shift Reinforcement Learning (TSRL), wherein both temporal, as well as spatial components are jointly learned. Moreover, TSRL does not require additional parameters to perform temporal learning. We show that TSRL outperforms the commonly used frame stacking heuristic on all of the Atari environments we test on while beating the SOTA for all except one of them. This investigation has implications in the robotics as well as sequential decision-making domains.</span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-other">
            <td class="schedule-time">10:00</td>
            <td class="schedule-slot">Coffee Break</td>
          </tr>
        
      
        
          <tr class="schedule-other">
            <td class="schedule-time">10:30</td>
            <td class="schedule-slot">Introduction</td>
          </tr>
        
      
        
          <tr class="schedule-session">
            <td class="schedule-time">15:40</td>
            <td class="schedule-slot">Session 1: Optimisation</td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Efficient Multi-Class Classification with Duet
            
              <span class="speakers-company">Shay Vargaftik, Yaniv Ben-Itzhak (VMware Research)</span>
              <span class="schedule-description program">Accordingly, we propose a new classifier termed Duet. Duet incorporates the advantages of bagging and boosting decision-tree-based ensemble methods (DTEMs) by using two classifiers instead of a monolithic one. A simple bagging model is trained using the entire training dataset and is responsible for capturing the easier concepts. Then, a boosting model is trained using only a fraction of the dataset representing the concepts the bagging model finds hard. To make the whole process resource efficient, we develop a new heuristic approach to rank data with respect to concepts that the bagging model finds hard. We use this approach, termed data instance predictability to determine the dataset fraction for the boosting model training. We implement Duet as a scikit-learn classifier. Evaluation using datasets from different domains and with different characteristics indicates that Duet offers a better tradeoff between classification accuracy and system performance than monolithic DTEMs. Moreover, in an evaluation over a resource-constrained Raspberry Pi 3 device Duet successfully completes all training tasks, where some monolithic models fail due to insufficient resources, indicating broader applicability of Duet to resource-constrained edge devices. Duet is a part of an effort for advancements in resource-efficient classification, and its scikit-learn implementation can be found in https://research.vmware.com/projects/efficient-machine-learning-classification. </span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Deep learning on microcontrollers: a study on deployment costs and challenges
            
              <span class="speakers-company">Filip Svoboda (University of Cambridge); JAVIER FERNANDEZ-MARQUES (University of Oxford); EDGAR LIBERIS, NICHOLAS LANE (University of Cambridge)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              syslrn: Learning What to Monitor for Efficient Anomaly Detection
            
              <span class="speakers-company">Davide Sanvito, Giuseppe Siracusano, Sharan Santhanam, Roberto Gonzalez, Roberto Bifulco (NEC Laboratories Europe)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
               BoGraph: Structured Bayesian Optimization From Logs for Expensive Systems with Many
            
              <span class="speakers-company">Sami Alabed, Eiko Yoneki (University of Cambridge)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-other">
            <td class="schedule-time">12:30</td>
            <td class="schedule-slot">Lunch Break / Poster Session </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time">13:45</td>
            <td class="schedule-slot">
            
            
              Keynote 1: Tianqi Chen
            
              <span class="speakers-company">CMU</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-session">
            <td class="schedule-time">14:30</td>
            <td class="schedule-slot">Session 2: Reinforcement Learning, Meta-Learning and Federated Learning</td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Reinforcement Learning for Resource Management in Multi-tenant Serverless Platforms
            
              <span class="speakers-company">Haoran Qiu, Weichao Mao, Archit Patke (University of Illinois at Urbana-Champaign); Chen Wang, Hubertus Franke (IBM Thomas J. Watson Research Center); Zbigniew Kalbarczyk, Tamer Başar, Ravishankar K. Iyer (University of Illinois at Urbana-Champaign)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Rapid Model Architecture Adaption for Meta-Learning
            
              <span class="speakers-company">Yiren Zhao (University of Cambridge); Xitong Gao (Shenzhen Institutes of Advanced Technology); Ilia Shumailov (University of Cambridge); Nicolo Fusi (Microsoft); Robert Mullins (University of Cambridge)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
               How Reinforcement Learning Systems Fail and What to do About It
            
              <span class="speakers-company"> Pouya Hamdanian (MIT); Malte Schwarzkopf (Brown University); Siddhartha Sen (Microsoft Research); Mohammad Alizadeh (MIT CSAIL)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              On the Impact of Device and Behavioral Heterogeneity in Federated Learning
            
              <span class="speakers-company">Ahmed M. Abdelmoniem (Queen Mary University of London); Chen-Yu Ho, Pantelis Papageorgiou, Marco Canini (KAUST)</span>
              <span class="schedule-description program"> Federated learning (FL) is becoming a popular paradigm for collaborative learning over distributed, private datasets owned by non-trusting entities. FL has seen successful deployment in production environments, and it has been adopted in services such as virtual keyboards, auto-completion, item recommendation, and several IoT applications. However, FL comes with the challenge of performing training over largely heterogeneous datasets, devices, and networks that are out of the control of the centralized FL server. Motivated by this inherent setting, we make a first step towards characterizing the impact of device and behavioral heterogeneity on the trained model. We conduct an extensive empirical study spanning close to 1.5K unique configurations on five popular FL benchmarks. Our analysis shows that these sources of heterogeneity have a major impact on both model performance and fairness, thus shedding light on the importance of considering heterogeneity in FL system design.</span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-other">
            <td class="schedule-time">15:50</td>
            <td class="schedule-slot">Coffee Break</td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time">16:15</td>
            <td class="schedule-slot">
            
            
              Keynote 2: Azalia Mirhoseini
            
              <span class="speakers-company">Google Brain</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-session">
            <td class="schedule-time">17:00</td>
            <td class="schedule-slot">Session 3: Applications</td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              slo-nns: Service Level Objective-Aware Neural Networks
            
              <span class="speakers-company"> Daniel Mendoza, Caroline Trippel (Stanford University)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              FlexHTTP: An Intelligent and Scalable HTTP Version Selection System
            
              <span class="speakers-company">Mengying Zhou, Zheng Li, Shihan Lin, Xin Wang, Yang Chen (Fudan University)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-talk">
            <td class="schedule-time"></td>
            <td class="schedule-slot">
            
            
              Live Video Analytics as a Service
            
              <span class="speakers-company">Guilherme Henrique Apostolo, Pablo Bauszat, Vinod Nigade, Henri E. Bal, Lin Wang (Vrije Universiteit Amsterdam)</span>
              <span class="schedule-description program"></span>
            </td>
          </tr>
        
      
        
          <tr class="schedule-other">
            <td class="schedule-time">18:00</td>
            <td class="schedule-slot">Wrapup</td>
          </tr>
        
      
    </tbody>
  </table>
</div>

          </section>
        
          <section class="sponsors section" id="sponsors">
            <h2 class="section-title">Sponsors</h2>
<br>
<ul class="sponsors-list">

  <li class="sponsor-item" itemscope itemtype="http://schema.org/Organization">
    <a href="https://research.facebook.com/" class="sponsor--link" itemprop="url" target="_blank">
      <img src="img/meta_logo.png" alt="Meta Research" class="photo" itemprop="image">
    </a>
  </li>

  <li class="sponsor-item" itemscope itemtype="http://schema.org/Organization">
    <a href="https://www.acm.org/" class="sponsor--link" itemprop="url" target="_blank">
      <img src="img/acm_logo.png" alt="ACM" class="photo" itemprop="image">
    </a>
  </li>

</ul>


          </section>
        
          <section class="committees section" id="committees">
            <h2 class="section-title">Committees</h2>

<h4>Workshop and TPC Chairs</h4>
<p>
<ul class="list">
    <li>Eiko Yoneki, University of Cambridge, <a href="https://www.cl.cam.ac.uk/~ey204/">https://www.cl.cam.ac.uk/~ey204/</a></li>
    <li>Luigi Nardi, Lund University/Stanford University, <a href="http://cs.lth.se/luigi-nardi/">http://cs.lth.se/luigi-nardi/</a></li>
</ul>
</p>
<p>
<h4>Technical Program Committee</h4>
<p>
    <ul class="list">
        <li>Aaron Zhao, University of Cambridge</li>
        <li>Ahmed M. Abdelmoniem, Queen Mary University of London</li>
        <li>Alexandros Koliousis, NCH</li>
        <li>Amir Payberah, KTH</li>
        <li>Amitabha Roy, Google</li>
        <li>Brooks Paige, UCL</li>
        <li>Chris Cummins, Facebook AI</li>
        <li>Daniel Goodman, Oracle </li>
        <li>Dawei Li, Amazon</li>
        <li>Dimitris Chatzopoulos, University College Dublin</li>
        <li>Fiodar Kazhamiaka,Stanford University</li>
        <li>Guoliang He, University of Cambridge</li>
        <li>Guy Leroy, MSR Cambridge</li>
        <li>Haitham Ammar, Huawei</li>
        <li>Hamed Haddadi, Imperial College London</li>
        <li>Holger Pirk, Imperial College London&lt;</li>
        <li>Jenny Huang, NVIDIA</li>
        <li>Jon Crowcroft, University of Cambridge</li>
        <li>Jose Cano, University of Glasgow</li>
        <li>Keshav Santhanam, Stanford University</li>
        <li>Laurent Bindschaedler, MIT</li>
        <li>Massimiliano Patacchiola, University of Cambridge</li>
        <li>Nikolas Ioannou, IBM Research - Zurich</li>
        <li>Paul Kelly, Imperial College London</li>
        <li>Paul Patras, University of Edinburgh</li>
        <li>Peter Pietzuch, Imperial College London</li>
        <li>Peter Triantafillou, University of Warwick</li>
        <li>Qian Li, Stanford University</li>
        <li>Sam Ainsworth, University of Edinburgh</li>
        <li>Sami Alabed, University of Cambridge</li>
        <li>Stratis Ioannidis, Northeastern University</li>
        <li>Thaleia Dimitra Doudali, IMDEA</li>
        <li>Valentin Radu, University of Sheffield</li>
        <li>Veljko Pejovic, University of Ljubljana</li>
        <li>Zheng Wang, University of Leeds</li>
        <li>Zhihao Jia, CMU</li>
    </ul>
</p>
</p>

<h4>Web Chair</h4>
<ul class="list">
    <li>Alexis Duque, Net AI</li>
</ul>

          </section>
        
          <section class="contact section" id="contact">
            <h2 class="section-title">Contact</h2>
<div>
  <p> For any question(s) related to EuroMLSys 2022, please contact the TPC Chairs <a href="mailto:eiko.yoneki@cl.cam.ac.uk">Eiko Yoneki</a> and <a href="mailto:Luigi.Nardi@cs.lth.se">Luigi Nardi</a>.
  <p><img src="/img/twitter.png" height="50px">Follow us on Twitter: <a href="https://twitter.com/euromlsys">@euromlsys</a>

</div>
          </section>
        

        <footer class="footer">
          <p>Sponsored by
            <a href="https://research.facebook.com/" class="sponsor" itemprop="url" target="_blank">
              <img src="img/meta_logo.png" height="60px" alt="Meta Research" class="photo" itemprop="image">
            </a>
            <a href="https://www.acm.org/" class="sponsor" itemprop="url" target="_blank">
              <img src="img/acm_logo.png" height="60px" alt="ACM" class="photo" itemprop="image">
            </a>
          </p>
          <p>Made with ♥ by EuroMLSys'22 team :).</p>
        </footer>
      </div>
    </div>
  </div>-->ent.write('<script src="/js/jquery.js"><\/script>')</script>
  
  
</body>
</html>
